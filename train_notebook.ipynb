{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sound-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  8 21:43:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P3    N/A /  N/A |    755MiB /  4042MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1345      G   /usr/lib/xorg/Xorg                 80MiB |\n",
      "|    0   N/A  N/A      2311      G   /usr/lib/xorg/Xorg                212MiB |\n",
      "|    0   N/A  N/A      2517      G   /usr/bin/gnome-shell              189MiB |\n",
      "|    0   N/A  N/A      3966      G   ...AAAAAAAAA= --shared-files       89MiB |\n",
      "|    0   N/A  N/A      5085      G   ...AAAAAAAA== --shared-files      135MiB |\n",
      "|    0   N/A  N/A      5735      G   .../debug.log --shared-files       39MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from pprint import pprint\n",
    "# model_names = timm.list_models(pretrained=True)\n",
    "# pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intermediate-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identified-trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataset': { 'train': { 'args': { 'csv_path': 'data/MELD/raw-audios-wav/train.csv',\n",
      "                                    'data_dir': 'data/MELD/raw-audios-wav/train/',\n",
      "                                    'duration': 6,\n",
      "                                    'format': '.wav',\n",
      "                                    'is_train': True,\n",
      "                                    'n_mels': 128,\n",
      "                                    'sr': 22050},\n",
      "                          'loader': { 'args': { 'batch_size': 4,\n",
      "                                                'drop_last': True,\n",
      "                                                'shuffle': True},\n",
      "                                      'name': 'DataLoader'},\n",
      "                          'name': 'AudioDataset'},\n",
      "               'val': { 'args': { 'csv_path': 'data/MELD/raw-audios-wav/val.csv',\n",
      "                                  'data_dir': 'data/MELD/raw-audios-wav/val/',\n",
      "                                  'duration': 6,\n",
      "                                  'format': '.wav',\n",
      "                                  'is_train': False,\n",
      "                                  'n_mels': 128,\n",
      "                                  'sr': 22050},\n",
      "                        'loader': { 'args': { 'batch_size': 4,\n",
      "                                              'drop_last': True,\n",
      "                                              'shuffle': True},\n",
      "                                    'name': 'DataLoader'},\n",
      "                        'name': 'AudioDataset'}},\n",
      "  'debug': False,\n",
      "  'gpus': '0',\n",
      "  'id': 'audio_effnet',\n",
      "  'loss': { 'args': {'alpha': 0.25, 'gamma': 2, 'reduce': True},\n",
      "            'name': 'FocalLoss'},\n",
      "  'metric': [{'args': None, 'name': 'F1Weighted'}],\n",
      "  'model': { 'args': { 'freeze_backbone': False,\n",
      "                       'from_pretrained': True,\n",
      "                       'name': 'tf_efficientnet_b0_ns',\n",
      "                       'num_classes': 7},\n",
      "             'name': 'BaseTimmModel'},\n",
      "  'optimizer': {'args': {'lr': 1e-05}, 'name': 'Adam'},\n",
      "  'pretrained': None,\n",
      "  'scheduler': { 'args': {'gamma': 0.2, 'last_epoch': -1, 'step_size': 3},\n",
      "                 'name': 'StepLR'},\n",
      "  'trainer': {'log_step': 1, 'nepochs': 10, 'val_step': 1}}\n",
      "\n",
      "Epoch   0\n",
      "-----------------------------------\n",
      "Training........\n",
      "  1%|▌                                        | 31/2497 [00:20<20:53,  1.97it/s]^C\n",
      "  1%|▌                                        | 31/2497 [00:22<29:28,  1.39it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 120, in <module>\n",
      "    train(config)\n",
      "  File \"train.py\", line 93, in train\n",
      "    val_dataloader=val_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 187, in train\n",
      "    self.train_epoch(epoch=epoch, dataloader=train_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 113, in train_epoch\n",
      "    self.scaler.step(self.optimizer)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py\", line 321, in step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/optim/adam.py\", line 84, in step\n",
      "    state = self.state[p]\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/tensor.py\", line 598, in __hash__\n",
      "    from torch.overrides import has_torch_function, handle_torch_function\n",
      "  File \"<frozen importlib._bootstrap>\", line 997, in _handle_fromlist\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --config configs/MELD_audio_effnet.yaml --gpus 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-theology",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessory-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "controversial-identity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1de369bba22a5d8b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1de369bba22a5d8b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-there",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
