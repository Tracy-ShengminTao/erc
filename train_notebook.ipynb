{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatal-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  7 21:25:10 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P0    N/A /  N/A |    816MiB /  4042MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1335      G   /usr/lib/xorg/Xorg                 80MiB |\n",
      "|    0   N/A  N/A      3288      G   /usr/lib/xorg/Xorg                199MiB |\n",
      "|    0   N/A  N/A      3659      G   /usr/bin/gnome-shell              190MiB |\n",
      "|    0   N/A  N/A      6388      G   ...AAAAAAAAA= --shared-files      190MiB |\n",
      "|    0   N/A  N/A      7448      G   ...AAAAAAAA== --shared-files      146MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incomplete-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from pprint import pprint\n",
    "# model_names = timm.list_models(pretrained=True)\n",
    "# pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bound-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pregnant-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataset': { 'train': { 'args': { 'csv_path': 'data/MELD/raw-audios/train.csv',\n",
      "                                    'data_dir': 'data/MELD/raw-audios/train/',\n",
      "                                    'duration': 8,\n",
      "                                    'format': '.mp3',\n",
      "                                    'is_train': True,\n",
      "                                    'n_mels': 128,\n",
      "                                    'sr': 22050},\n",
      "                          'loader': { 'args': { 'batch_size': 2,\n",
      "                                                'drop_last': True,\n",
      "                                                'shuffle': True},\n",
      "                                      'name': 'DataLoader'},\n",
      "                          'name': 'AudioDataset'},\n",
      "               'val': { 'args': { 'csv_path': 'data/MELD/raw-audios/val.csv',\n",
      "                                  'data_dir': 'data/MELD/raw-audios/val/',\n",
      "                                  'duration': 8,\n",
      "                                  'format': '.mp3',\n",
      "                                  'is_train': False,\n",
      "                                  'n_mels': 128,\n",
      "                                  'sr': 22050},\n",
      "                        'loader': { 'args': {'batch_size': 2, 'shuffle': True},\n",
      "                                    'name': 'DataLoader'},\n",
      "                        'name': 'AudioDataset'}},\n",
      "  'debug': False,\n",
      "  'gpus': '0',\n",
      "  'id': 'audio_effnet_b0',\n",
      "  'loss': {'args': None, 'name': 'FocalLoss'},\n",
      "  'metric': [{'args': None, 'name': 'Accuracy'}],\n",
      "  'model': { 'args': { 'freeze_backbone': False,\n",
      "                       'from_pretrained': True,\n",
      "                       'name': 'tf_efficientnet_b0_ns',\n",
      "                       'num_classes': 7},\n",
      "             'name': 'BaseTimmModel'},\n",
      "  'optimizer': {'args': {'lr': 0.0001}, 'name': 'Adam'},\n",
      "  'pretrained': None,\n",
      "  'scheduler': { 'args': {'gamma': 0.2, 'last_epoch': -1, 'step_size': 3},\n",
      "                 'name': 'StepLR'},\n",
      "  'trainer': {'log_step': 1, 'nepochs': 10, 'val_step': 1}}\n",
      "\n",
      "Epoch   0\n",
      "-----------------------------------\n",
      "Training........\n",
      "  1%|▍                                      | 50/4994 [00:45<1:07:13,  1.23it/s]^C\n",
      "  1%|▍                                      | 50/4994 [00:46<1:16:35,  1.08it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/librosa/core/audio.py\", line 146, in load\n",
      "    with sf.SoundFile(path) as sf_desc:\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/soundfile.py\", line 629, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/soundfile.py\", line 1184, in _open\n",
      "    \"Error opening {0!r}: \".format(self.name))\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/soundfile.py\", line 1357, in _error_check\n",
      "    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\n",
      "RuntimeError: Error opening 'data/MELD/raw-audios/train/dia623_utt14.mp3': File contains data in an unknown format.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 120, in <module>\n",
      "    train(config)\n",
      "  File \"train.py\", line 93, in train\n",
      "    val_dataloader=val_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 178, in train\n",
      "    self.train_epoch(epoch=epoch, dataloader=train_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 87, in train_epoch\n",
      "    for i, (inp, lbl) in enumerate(progress_bar):\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/tqdm/std.py\", line 1170, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"./libs/datasets/audio.py\", line 66, in __getitem__\n",
      "    y = self.get_audio(audio_path_w_format)\n",
      "  File \"./libs/datasets/audio.py\", line 25, in get_audio\n",
      "    y, _ = lb.load(audio_path, sr=self.sr, duration=self.duration, offset=offset)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/librosa/core/audio.py\", line 163, in load\n",
      "    y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/librosa/core/audio.py\", line 187, in __audioread_load\n",
      "    with audioread.audio_open(path) as input_file:\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/audioread/__init__.py\", line 107, in audio_open\n",
      "    backends = available_backends()\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/audioread/__init__.py\", line 86, in available_backends\n",
      "    if ffdec.available():\n",
      "  File \"/home/kvu/erc/venv/lib/python3.6/site-packages/audioread/ffdec.py\", line 115, in available\n",
      "    proc.wait()\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1477, in wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1424, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --config configs/MELD_audio_effnet.yaml --gpus 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-superior",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "molecular-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cleared-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 215831), started 2:26:37 ago. (Use '!kill 215831' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-97e89e674bdf700\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-97e89e674bdf700\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-industry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
