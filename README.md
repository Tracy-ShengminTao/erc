# ERC (Emotion Recognition in Coversation)

This repo is is to reach the SOTA of multimodal ERC challenges. The authors aim to publish a paper in 2021. 

The datasets to work on include

1. [MELD](https://affective-meld.github.io/) (ongoing)

    Go to the directory `MELD` to see the ongoing results.

2. [IEMOCAP](https://sail.usc.edu/iemocap/) (not yet started)


## Prerequisites

* An x86-64 Unix or Unix-like machines 
* Python 3.6x, 3.7x, or 3.8x

## Installing the necessary python packages

Since we deal with multimodal data, there are three different packages to install. Ideally, all of them should be in separate repos but I just put all of them here at the moment.

1. Vision

    Go to the directory `cltl-face-all` and follow the instructions.

2. Text

    TBD

3. Audio

    TBD


## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
1. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
1. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
1. Push to the Branch (`git push origin feature/AmazingFeature`)
1. Open a Pull Request

## Authors
* Taewoon Kim (t.kim@vu.nl)

## License
[MIT](https://choosealicense.com/licenses/mit/)
