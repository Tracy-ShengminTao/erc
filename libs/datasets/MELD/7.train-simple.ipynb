{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from utils import get_face_utts\n",
    "\n",
    "with open('configs/paths.yaml', 'r') as stream:\n",
    "    PATHS = yaml.safe_load(stream)\n",
    "\n",
    "with open(PATHS['ANNOTATIONS']['all'], 'r') as stream:\n",
    "    datasets = yaml.safe_load(stream)\n",
    "\n",
    "utts = get_face_utts(datasets, PATHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/train.yaml', 'r') as stream:\n",
    "    train_config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MeldDataset',\n",
       " 'args': {'choose_frames': 'random_consecutive', 'num_frames': 1},\n",
       " 'loader': {'name': '<dataloader class name>',\n",
       "  'args': {'<dataloader argument keyword>': '<argument value>'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config['dataset']['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.squeeze(images_batch)\n",
    "# x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# from matplotlib import animation\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# # np array with shape (frames, height, width, channels)\n",
    "# video = x\n",
    "\n",
    "# fig = plt.figure()\n",
    "# im = plt.imshow(video[0,:,:,:])\n",
    "\n",
    "# plt.close() # this is required to not display the generated image\n",
    "\n",
    "# def init():\n",
    "#     im.set_data(video[0,:,:,:])\n",
    "\n",
    "# def animate(i):\n",
    "#     im.set_data(video[i,:,:,:])\n",
    "#     return im\n",
    "\n",
    "# anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
    "#                                interval=50)\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as tvtf\n",
    "\n",
    "\n",
    "if train_config['dataset']['train']['name'] == 'MeldDataset':\n",
    "    from erc.datasets.meld import MeldDataset as Dataset\n",
    "else:\n",
    "    pass\n",
    "\n",
    "ds_train_kwargs = {'list_vid_paths':[os.path.join(PATHS['FACE_VIDEOS']['train'], utt) + '.mp4' for utt in utts['train']],\n",
    "            'labels':[datasets['train'][utt]['Emotion'].lower() for utt in utts['train']], \n",
    "            **train_config['dataset']['train']['args']}\n",
    "\n",
    "ds_train = Dataset(**ds_train_kwargs)\n",
    "\n",
    "ds_train_gen = torch.utils.data.DataLoader(ds_train, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "class BaseTimmModel(nn.Module):\n",
    "    \"\"\"Some Information about BaseTimmModel\"\"\"\n",
    "\n",
    "    def _init_(self, num_classes, name, freeze_backbone=False, pretrained=True):\n",
    "        super()._init_()\n",
    "        self.model = timm.create_model(name, pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseTimmModel(num_classes=7, name='efficientnet_b0', pretrained=True)\n",
    "num_epoch = 10\n",
    "for epoch in range(num_epoch):\n",
    "    for image_batch, label_batch in ds_train_gen:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_history = []\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in ds_train_gen[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # Get model outputs and calculate loss\n",
    "                # Special case for inception because in training it has an auxiliary output. In train\n",
    "                #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                #   but in testing we only consider the final output.\n",
    "                if is_inception and phase == 'train':\n",
    "                    # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                    outputs, aux_outputs = model(inputs)\n",
    "                    loss1 = criterion(outputs, labels)\n",
    "                    loss2 = criterion(aux_outputs, labels)\n",
    "                    loss = loss1 + 0.4*loss2\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if phase == 'val':\n",
    "            val_acc_history.append(epoch_acc)\n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('dev-python-3.7')",
   "language": "python",
   "name": "python37964bitdevpython378e162af75d134820b03d49898b79756f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
