{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markdown_table(array):\n",
    "    \"\"\" Input: Python list with rows of table as lists\n",
    "               First element as header. \n",
    "        Output: String to put into a .md file \n",
    "\n",
    "    Ex Input: \n",
    "        [[\"Name\", \"Age\", \"Height\"],\n",
    "         [\"Jake\", 20, 5'10],\n",
    "         [\"Mary\", 21, 5'7]] \n",
    "    \"\"\"\n",
    "\n",
    "    markdown = \"\\n\" + \"| \"\n",
    "\n",
    "    for e in array[0]:\n",
    "        to_add = \" \" + str(e) + \" |\"\n",
    "        markdown += to_add\n",
    "    markdown += \"\\n\"\n",
    "\n",
    "    markdown += '|'\n",
    "    for i in range(len(array[0])):\n",
    "        markdown += \"-------------- | \"\n",
    "    markdown += \"\\n\"\n",
    "\n",
    "    for entry in array[1:]:\n",
    "        markdown += \"| \"\n",
    "        for e in entry:\n",
    "            to_add = str(e) + \" | \"\n",
    "            markdown += to_add\n",
    "        markdown += \"\\n\"\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MELD\n",
      "\n",
      "|  SPLIT | SUM | neutral | joy | surprise | anger | sadness | disgust | fear |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 9989 | 4710 | 1743 | 1205 | 1109 | 683 | 271 | 268 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | joy | anger | surprise | sadness | fear | disgust |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 1109 | 470 | 163 | 153 | 150 | 111 | 40 | 22 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | joy | anger | surprise | sadness | disgust | fear |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 2610 | 1256 | 402 | 345 | 281 | 208 | 68 | 50 | \n",
      "\n",
      "### IEMOCAP\n",
      "\n",
      "|  SPLIT | SUM | undecided | neutral | frustration | sadness | anger | excited | happiness | surprise | fear | disgust | other |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 6468 | 1587 | 1167 | 1149 | 739 | 711 | 620 | 392 | 76 | 23 | 2 | 2 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | undecided | frustration | anger | neutral | excited | sadness | happiness | surprise | fear | other |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 1401 | 400 | 319 | 222 | 157 | 122 | 100 | 60 | 13 | 7 | 1 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | undecided | neutral | frustration | excited | sadness | anger | happiness | surprise | fear |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 2170 | 520 | 384 | 381 | 299 | 245 | 170 | 143 | 18 | 10 | \n",
      "\n",
      "### EmoryNLP\n",
      "\n",
      "|  SPLIT | SUM | neutral | joyful | scared | mad | peaceful | powerful | sad |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 9934 | 3034 | 2184 | 1285 | 1076 | 900 | 784 | 671 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | joyful | scared | mad | powerful | peaceful | sad |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 1344 | 393 | 289 | 178 | 143 | 134 | 132 | 75 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | joyful | scared | peaceful | powerful | mad | sad |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 1328 | 349 | 282 | 182 | 159 | 145 | 113 | 98 | \n",
      "\n",
      "### DailyDialog\n",
      "\n",
      "|  SPLIT | SUM | neutral | happiness | surprise | sadness | anger | disgust | fear |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 87170 | 72143 | 11182 | 1600 | 969 | 827 | 303 | 146 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | happiness | surprise | sadness | anger | fear | disgust |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 8069 | 7108 | 684 | 107 | 79 | 77 | 11 | 3 | \n",
      "\n",
      "\n",
      "|  SPLIT | SUM | neutral | happiness | anger | surprise | sadness | disgust | fear |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 7740 | 6321 | 1019 | 118 | 116 | 102 | 47 | 17 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "stats = {}\n",
    "for DATASET in ['MELD', 'IEMOCAP', 'EmoryNLP', 'DailyDialog']:\n",
    "    stats[DATASET] = {}\n",
    "    with open(f\"../{DATASET}/labels.json\", 'r') as stream:\n",
    "        labels = json.load(stream)\n",
    "    for SPLIT in ['train', 'val', 'test']:\n",
    "        stats[DATASET][SPLIT] = dict(Counter(list(labels[SPLIT].values())))\n",
    "\n",
    "for DATASET in ['MELD', 'IEMOCAP', 'EmoryNLP', 'DailyDialog']:\n",
    "    print(f\"### {DATASET}\")\n",
    "    for SPLIT in ['train', 'val', 'test']:\n",
    "        table = []\n",
    "\n",
    "        bar = dict(sorted(stats[DATASET][SPLIT].items()))\n",
    "        bar['SUM'] = sum(list(bar.values()))\n",
    "        bar = dict(sorted(bar.items(), key=lambda item: -item[1]))\n",
    "        \n",
    "        table.append(['SPLIT'])\n",
    "        for emotion in bar.keys():\n",
    "            table[0].append(emotion)\n",
    "        table.append([f\"{SPLIT}\"])\n",
    "        for emotion in bar.values():\n",
    "            table[1].append(emotion)\n",
    "            \n",
    "        print(make_markdown_table(table))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MELD\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 1038 | 9989 | 9.623 | 5.843 | 1 | 24 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 114 | 1109 | 9.728 | 5.434 | 1 | 23 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 280 | 2610 | 9.321 | 5.701 | 1 | 33 | \n",
      "\n",
      "### IEMOCAP\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 100 | 6468 | 64.68 | 22.815 | 24 | 167 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 20 | 1401 | 70.05 | 19.296 | 41 | 110 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 31 | 2170 | 70.0 | 20.916 | 32 | 130 | \n",
      "\n",
      "### EmoryNLP\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 713 | 9934 | 13.933 | 5.546 | 5 | 25 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 99 | 1344 | 13.576 | 5.878 | 5 | 25 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 85 | 1328 | 15.624 | 5.605 | 5 | 25 | \n",
      "\n",
      "### DailyDialog\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 11118 | 87170 | 7.84 | 4.008 | 2 | 35 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 1000 | 8069 | 8.069 | 3.883 | 2 | 31 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of dialogues in total | number of utterances in total | number of utterances per dialogue (mean) | number of utterances per dialogue (std.) | number of utterances per dialogue (min) | number of utterances per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 1000 | 7740 | 7.74 | 3.842 | 2 | 26 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "stats = {}\n",
    "for DATASET in ['MELD', 'IEMOCAP', 'EmoryNLP', 'DailyDialog']:\n",
    "    stats[DATASET] = {}\n",
    "    with open(f\"../{DATASET}/utterance-ordered.json\", 'r') as stream:\n",
    "        diautt_ordered = json.load(stream)\n",
    "\n",
    "    print(f\"### {DATASET}\")\n",
    "    for SPLIT in ['train', 'val', 'test']:\n",
    "        table = []     \n",
    "        table.append(['SPLIT', \n",
    "                      'number of dialogues in total', \n",
    "                      'number of utterances in total',\n",
    "                     'number of utterances per dialogue (mean)',\n",
    "                     'number of utterances per dialogue (std.)',\n",
    "                     'number of utterances per dialogue (min)',\n",
    "                     'number of utterances per dialogue (max)'])\n",
    "\n",
    "        \n",
    "        num_utts_all = []\n",
    "        \n",
    "        for diaid, uttids in diautt_ordered[SPLIT].items():\n",
    "            num_utts = len(uttids)\n",
    "            num_utts_all.append(num_utts)\n",
    "        \n",
    "        table.append([SPLIT, \n",
    "                      len(diautt_ordered[SPLIT].keys()), \n",
    "                      len([v for key, val in diautt_ordered[SPLIT].items() for v in val]),\n",
    "                     round(np.mean(np.array(num_utts_all)),3),\n",
    "                     round(np.std(np.array(num_utts_all)),3),\n",
    "                     round(np.min(np.array(num_utts_all)),3),\n",
    "                     round(np.max(np.array(num_utts_all)),3)])\n",
    "\n",
    "            \n",
    "        print(make_markdown_table(table))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334b19ce5ce14af6b13f1c1e386aa173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MELD\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 110476 | 106.432 | 70.518 | 1 | 419 | 11.097 | 3.958 | 1.0 | 43.0 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 12268 | 107.614 | 63.611 | 5 | 302 | 11.084 | 2.938 | 2.5 | 21.0 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 29773 | 106.332 | 71.653 | 2 | 544 | 11.319 | 3.66 | 2.0 | 25.5 | \n",
      "\n",
      "### IEMOCAP\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 93743 | 937.43 | 305.407 | 377 | 1828 | 14.929 | 3.563 | 7.896 | 31.359 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 21659 | 1082.95 | 258.06 | 529 | 1517 | 15.888 | 3.149 | 10.427 | 22.163 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 33399 | 1077.387 | 309.548 | 469 | 1748 | 15.733 | 3.186 | 9.654 | 22.309 | \n",
      "\n",
      "### EmoryNLP\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 141325 | 198.212 | 92.764 | 25 | 569 | 14.527 | 5.124 | 3.571 | 46.143 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 18303 | 184.879 | 97.146 | 31 | 455 | 13.632 | 4.835 | 4.556 | 27.667 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 18334 | 215.694 | 89.663 | 71 | 450 | 14.214 | 4.125 | 6.429 | 30.0 | \n",
      "\n",
      "### DailyDialog\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 1214780 | 109.262 | 76.439 | 5 | 855 | 13.712 | 6.611 | 2.5 | 145.0 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 111416 | 111.416 | 69.889 | 8 | 645 | 14.001 | 7.091 | 3.8 | 110.5 | \n",
      "\n",
      "\n",
      "|  SPLIT | number of tokens in total | number of tokens per dialogue (mean) | number of tokens per dialogue (std.) | number of tokens per dialogue (min) | number of tokens per dialogue (max) | number of tokens per utterance per dialogue (mean) | number of tokens per utterance per dialogue (std.) | number of tokens per utterance per dialogue (min) | number of tokens per utterance per dialogue (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 109344 | 109.344 | 73.146 | 7 | 462 | 14.036 | 7.329 | 3.5 | 112.0 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from glob import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_utt(path):\n",
    "    with open(path, 'r') as stream:\n",
    "        foo = json.load(stream)\n",
    "    return foo['Utterance']\n",
    "\n",
    "\n",
    "for DATASET in tqdm(['MELD', 'IEMOCAP', 'EmoryNLP', 'DailyDialog']):    \n",
    "    print(f\"### {DATASET}\")\n",
    "    with open(f\"../{DATASET}/utterance-ordered.json\", 'r') as stream:\n",
    "        diautt_ordered = json.load(stream)\n",
    "\n",
    "    num_tokens = {}\n",
    "    for SPLIT in ['train', 'val', 'test']:\n",
    "        num_tokens[SPLIT] = {}\n",
    "        \n",
    "        for diaid, uttids in diautt_ordered[SPLIT].items():\n",
    "            utts = [load_utt(os.path.join(f\"../{DATASET}/raw-texts/{SPLIT}/{uttid}.json\")) for uttid in uttids]\n",
    "            tokens = [len(nltk.word_tokenize(utt)) for utt in utts]\n",
    "            num_tokens[SPLIT][diaid] = tokens\n",
    "            pass\n",
    "        \n",
    "        table = []\n",
    "        table.append(['SPLIT', \n",
    "                      'number of tokens in total', \n",
    "                      'number of tokens per dialogue (mean)', \n",
    "                      'number of tokens per dialogue (std.)',\n",
    "                      'number of tokens per dialogue (min)',\n",
    "                      'number of tokens per dialogue (max)',\n",
    "                      'number of tokens per utterance per dialogue (mean)', \n",
    "                      'number of tokens per utterance per dialogue (std.)',\n",
    "                     'number of tokens per utterance per dialogue (min)',\n",
    "                     'number of tokens per utterance per dialogue (max)'])\n",
    "        table.append([SPLIT, \n",
    "                      np.sum(np.array([bar for foo in list(num_tokens[SPLIT].values()) for bar in foo])),\n",
    "                      round(np.mean(np.array([np.sum(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                      round(np.std(np.array([np.sum(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                      round(np.min(np.array([np.sum(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                      round(np.max(np.array([np.sum(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                      round(np.mean(np.array([np.mean(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                      round(np.std(np.array([np.mean(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                     round(np.min(np.array([np.mean(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3),\n",
    "                     round(np.max(np.array([np.mean(np.array(numtokens)) for diaid, numtokens in num_tokens[SPLIT].items()])),3)])\n",
    "        print(make_markdown_table(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "av.error.InvalidDataError"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av.InvalidDataError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Format mov,mp4,m4a,3gp,3g2,mj2 detected only with low score of 1, misdetection possible!\n",
      "moov atom not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 75.175 | 58.239 | 2 | 984 | 24.005 | 0.068 | 24 | 25 | 3.132 | 2.425 | 0.083 | 41.0 | \n",
      "\n",
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 74.746 | 59.78 | 2 | 684 | 24.005 | 0.073 | 24 | 25 | 3.114 | 2.491 | 0.083 | 28.5 | \n",
      "\n",
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 78.949 | 182.422 | 2 | 7312 | 24.005 | 0.074 | 24 | 25 | 3.289 | 7.601 | 0.083 | 304.667 | \n",
      "\n",
      "### IEMOCAP\n",
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| train | 135.335 | 88.957 | 14 | 874 | 30.153 | 0.365 | 30 | 32 | 4.502 | 2.973 | 0.467 | 29.133 | \n",
      "\n",
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| val | 135.064 | 87.758 | 24 | 544 | 30.158 | 0.372 | 30 | 32 | 4.493 | 2.933 | 0.75 | 18.133 | \n",
      "\n",
      "\n",
      "|  SPLIT | num_frames (mean) | num_frames (std.) | num_frames (min) | num_frames (max) | fps (mean) | fps (std.) | fps (min) | fps (max) | duration in sec (mean) | duration in sec (std.) | duration in sec (min) | duration in sec (max) |\n",
      "|-------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- | \n",
      "| test | 132.25 | 102.309 | 25 | 1024 | 30.209 | 0.413 | 30 | 32 | 4.396 | 3.419 | 0.781 | 34.133 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import json\n",
    "import av\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "for DATASET in ['MELD', 'IEMOCAP']:\n",
    "    print(f\"### {DATASET}\")\n",
    "    for SPLIT in ['train', 'val', 'test']:\n",
    "        stats = {}\n",
    "        vidpaths = glob(f\"../{DATASET}/raw-videos/{SPLIT}/*\")\n",
    "\n",
    "        stats['num_frames'] = []\n",
    "        stats['fps'] = []\n",
    "        stats['duration_sec'] = []\n",
    "        \n",
    "        for path in vidpaths:\n",
    "            try:\n",
    "                container = av.open(path)\n",
    "                videostream = container.streams.video[0]\n",
    "                num_frames = videostream.frames\n",
    "                fps = int(round(float(videostream.average_rate)))\n",
    "                duration_sec = videostream.frames / fps\n",
    "\n",
    "                stats['num_frames'].append(num_frames)\n",
    "                stats['fps'].append(fps)\n",
    "                stats['duration_sec'].append(duration_sec)\n",
    "            except av.InvalidDataError as e:\n",
    "                pass\n",
    "        \n",
    "        stats['num_frames'] = np.array(stats['num_frames'])\n",
    "        stats['fps'] = np.array(stats['fps'])\n",
    "        stats['duration_sec'] = np.array(stats['duration_sec'])\n",
    "        \n",
    "    \n",
    "        table = []     \n",
    "        table.append(['SPLIT', \n",
    "                      'num_frames (mean)',\n",
    "                      'num_frames (std.)',\n",
    "                      'num_frames (min)',\n",
    "                      'num_frames (max)',\n",
    "\n",
    "                      'fps (mean)',\n",
    "                      'fps (std.)',\n",
    "                      'fps (min)',\n",
    "                      'fps (max)',\n",
    "\n",
    "                      'duration in sec (mean)',\n",
    "                      'duration in sec (std.)',\n",
    "                      'duration in sec (min)',\n",
    "                      'duration in sec (max)'])\n",
    "        \n",
    "        table.append([SPLIT, \n",
    "                      round(np.mean(stats['num_frames']),3),\n",
    "                      round(np.std(stats['num_frames']),3),\n",
    "                      round(np.min(stats['num_frames']),3),\n",
    "                      round(np.max(stats['num_frames']),3),\n",
    "\n",
    "                      round(np.mean(stats['fps']),3),\n",
    "                      round(np.std(stats['fps']),3),\n",
    "                      round(np.min(stats['fps']),3),\n",
    "                      round(np.max(stats['fps']),3),\n",
    "\n",
    "                      round(np.mean(stats['duration_sec']),3),\n",
    "                      round(np.std(stats['duration_sec']),3),\n",
    "                      round(np.min(stats['duration_sec']),3),\n",
    "                      round(np.max(stats['duration_sec']),3)])\n",
    "\n",
    "        print(make_markdown_table(table))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
