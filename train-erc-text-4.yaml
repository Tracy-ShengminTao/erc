DATASET: IEMOCAP
model_checkpoint: roberta-large
num_past_utterances: 1000
num_future_utterances: 0
BATCH_SIZE: 4
HP_ONLY_UPTO: 10
NUM_TRAIN_EPOCHS: 5
WEIGHT_DECAY: 0.01
WARMUP_RATIO: 0.2
HP_N_TRIALS: 5
SEEDS:
- 0
- 1
- 2
- 3
- 4
ADD_BOU: true
ADD_EOU: true
ADD_SPEAKER_TOKENS: true
REPLACE_NAMES_IN_UTTERANCES: false # having this true had a very bad effect. So weird.
SPEAKER_SPLITS:
 - train
 - val
 - test

max_model_input_size: 512
ROOT_DIR: './multimodal-datasets/' # dir for the datasets 
