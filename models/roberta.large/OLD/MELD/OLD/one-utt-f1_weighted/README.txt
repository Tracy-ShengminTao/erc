Backprop is done to minimize the training cross entropy loss, but the model
with the highest validation f1_weighted is chosen.
No Speakers added to the utterances.

Only one speaker utterance used.

For example:
<s>Hi how are you?</s>

<s> is always prepended to the entire sequence. It works as a BOS and CLS.
