{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "VISUAL_FEATURES_PATH = '/home/tk/datasets/MELD/visual-features/smaller-dataset/all/'\n",
    "VIDS_DIR = \"/home/tk/datasets/MELD/MELD.Raw/train/train_splits/\"\n",
    "DATASET_PATH = '/home/tk/datasets/MELD/visual-features/smaller-dataset/datasets.json'\n",
    "\n",
    "visual_features = glob(os.path.join(VISUAL_FEATURES_PATH, '*.npy'))\n",
    "visual_features = {os.path.basename(vf).split('.npy')[0] : np.load(vf, allow_pickle=True).item() for vf in visual_features}\n",
    "\n",
    "with open(DATASET_PATH, 'r') as stream:\n",
    "    datasets = json.load(stream)\n",
    "\n",
    "datasets = datasets['large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Out of the 584 number of videos (utterances),\nThere are in total of 31 unique speakers mentioned\n\n['Ben', 'Chandler', 'Charlie', 'Chip', 'Danny', 'Dr. Green', 'Dr. Johnson', 'Dr. Ledbetter', 'Dr. Rhodes', 'Hoshi', 'Joey', 'Julie', 'Katie', 'Leslie', 'Marc', 'Mike', 'Mischa', 'Mona', \"Mona's Date\", 'Monica', 'Pete', 'Phoebe', 'Rachel', 'Receptionist', 'Richard', 'Rick', 'Ross', 'Student', 'The Assistant Director', 'The Director', 'Tom']\n\nand 19645 faces detected\n"
     ]
    }
   ],
   "source": [
    "FACE_PROB = 0.975\n",
    "EVERY_N_FRAME = 4\n",
    "# SPEAKERS_OF_INTEREST = ['Chandler', 'Joey', 'Monica', 'Phoebe', 'Rachel', 'Ross']\n",
    "DATASET_chosen = 'train'\n",
    "dataset_chosen = datasets[DATASET_chosen]\n",
    "\n",
    "speakers_mentioned = []\n",
    "embeddings_all = []\n",
    "\n",
    "# This is gonna help us to find back to the source frame and video\n",
    "idx2source = {}\n",
    "embeddings_all = []\n",
    "bboxes_all = []\n",
    "landmarks_all = []\n",
    "\n",
    "count = 0\n",
    "for diautt, annot in dataset_chosen.items():\n",
    "    # There is one face annotated in the entire video.\n",
    "    # We are not even sure if the face is actually there or not.\n",
    "    # Even though the face is there, we are not sure which frame number it is.\n",
    "\n",
    "    # if annot['Speaker'] not in SPEAKERS_OF_INTEREST:\n",
    "    #     continue\n",
    "\n",
    "    for framenum, list_of_findings in visual_features[diautt].items():\n",
    "        if framenum % EVERY_N_FRAME != 0:\n",
    "            continue\n",
    "        for finding in list_of_findings:\n",
    "            if finding['bbox'][-1] < FACE_PROB:\n",
    "                continue\n",
    "            \n",
    "            embeddings_all.append(finding['embedding'])\n",
    "            bboxes_all.append(finding['bbox'])\n",
    "            landmarks_all.append(finding['landmark'])\n",
    "            idx2source[count] = {'diautt':diautt, 'frame': framenum}\n",
    "            count+=1\n",
    "            speakers_mentioned.append(annot['Speaker'])\n",
    "\n",
    "assert len(embeddings_all) == len(bboxes_all) == len(landmarks_all) == \\\n",
    "        len(idx2source)\n",
    "\n",
    "speakers_mentioned = sorted(list(set(speakers_mentioned)))\n",
    "\n",
    "print(f\"Out of the {len(dataset_chosen)} number of videos (utterances),\")\n",
    "print(f\"There are in total of {len(speakers_mentioned)} unique speakers mentioned\")\n",
    "print()\n",
    "print(speakers_mentioned)\n",
    "print()\n",
    "print(f\"and {len(embeddings_all)} faces detected\")\n",
    "\n",
    "np.save('./DEBUG/embeddings-all.npy', embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimated number of clusters: 57\n",
      "Estimated number of noise points: 5350\n",
      "Silhouette Coefficient: 0.129\n",
      "Number of faces that are clustered: 14295\n",
      "\n",
      " label -1 \t has 5350 counts\n",
      " label 0 \t has 1014 counts\n",
      " label 1 \t has 1821 counts\n",
      " label 2 \t has 1318 counts\n",
      " label 3 \t has 2013 counts\n",
      " label 4 \t has 2470 counts\n",
      " label 5 \t has 1728 counts\n",
      " label 6 \t has 126 counts\n",
      " label 7 \t has 20 counts\n",
      " label 8 \t has 21 counts\n",
      " label 9 \t has 121 counts\n",
      " label 10 \t has 24 counts\n",
      " label 11 \t has 1393 counts\n",
      " label 12 \t has 72 counts\n",
      " label 13 \t has 23 counts\n",
      " label 14 \t has 89 counts\n",
      " label 15 \t has 155 counts\n",
      " label 16 \t has 24 counts\n",
      " label 17 \t has 20 counts\n",
      " label 18 \t has 25 counts\n",
      " label 19 \t has 57 counts\n",
      " label 20 \t has 72 counts\n",
      " label 21 \t has 27 counts\n",
      " label 22 \t has 61 counts\n",
      " label 23 \t has 27 counts\n",
      " label 24 \t has 21 counts\n",
      " label 25 \t has 20 counts\n",
      " label 26 \t has 22 counts\n",
      " label 27 \t has 48 counts\n",
      " label 28 \t has 49 counts\n",
      " label 29 \t has 30 counts\n",
      " label 30 \t has 32 counts\n",
      " label 31 \t has 159 counts\n",
      " label 32 \t has 51 counts\n",
      " label 33 \t has 41 counts\n",
      " label 34 \t has 26 counts\n",
      " label 35 \t has 22 counts\n",
      " label 36 \t has 50 counts\n",
      " label 37 \t has 45 counts\n",
      " label 38 \t has 43 counts\n",
      " label 39 \t has 31 counts\n",
      " label 40 \t has 25 counts\n",
      " label 41 \t has 23 counts\n",
      " label 42 \t has 36 counts\n",
      " label 43 \t has 20 counts\n",
      " label 44 \t has 23 counts\n",
      " label 45 \t has 150 counts\n",
      " label 46 \t has 28 counts\n",
      " label 47 \t has 30 counts\n",
      " label 48 \t has 114 counts\n",
      " label 49 \t has 118 counts\n",
      " label 50 \t has 128 counts\n",
      " label 51 \t has 27 counts\n",
      " label 52 \t has 24 counts\n",
      " label 53 \t has 23 counts\n",
      " label 54 \t has 38 counts\n",
      " label 55 \t has 37 counts\n",
      " label 56 \t has 40 counts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = np.stack(embeddings_all)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "# DBSCAN uses euclidean distance between the data points.\n",
    "# TODO: find a way to replace it with angle distance.\n",
    "# eps and min_samples are hyper parameters that you have to tune.\n",
    "# At the moment 0.75 and 10, respectively, works decent.\n",
    "db = DBSCAN(eps=0.8, min_samples=20).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "print(f\"Number of faces that are clustered: {len(embeddings_all) - n_noise_}\")\n",
    "print()\n",
    "\n",
    "(label_num, counts) = np.unique(labels, return_counts=True)\n",
    "\n",
    "for l, c in zip(label_num, counts):\n",
    "    print(f\" label {l} \\t has {c} counts\")\n",
    "\n",
    "np.save('./DEBUG/embeddings-clusters.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=19645.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd83c1059c2c44e4a996f191a9fc150e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "VIDS_DIR = \"/home/tk/datasets/MELD/MELD.Raw/train/train_splits/\"\n",
    "NUM_MAX_VID_PER_LABEL = 25\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import av\n",
    "import random\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "\n",
    "labels = np.load(\"./DEBUG/embeddings-clusters.npy\")\n",
    "\n",
    "\n",
    "shutil.rmtree('./DEBUG/faces/', ignore_errors=True)\n",
    "\n",
    "assert len(embeddings_all) == len(bboxes_all) == len(landmarks_all) == \\\n",
    "        len(idx2source) == len(labels)\n",
    "\n",
    "\n",
    "list_all = []\n",
    "\n",
    "\n",
    "indices = list(idx2source.keys())\n",
    "for idx in indices:\n",
    "    label_ = labels[idx]\n",
    "\n",
    "    embedding_ = embeddings_all[idx]\n",
    "    bbox_ = bboxes_all[idx]\n",
    "    landmark_ = landmarks_all[idx]\n",
    "    source_ = idx2source[idx]\n",
    "\n",
    "    to_append = {'label': label_, \n",
    "                'embedding': embedding_,\n",
    "                 'bbox': bbox_,\n",
    "                 'landmark': landmark_,\n",
    "                 'diautt': source_['diautt'],\n",
    "                 'frame': source_['frame']}\n",
    "\n",
    "    list_all.append(to_append)\n",
    "\n",
    "\n",
    "assert len(list_all) == len(labels)\n",
    "\n",
    "random.shuffle(list_all)\n",
    "\n",
    "\n",
    "fd = FaceDetection(device='cpu', face_detector='sfd')\n",
    "\n",
    "labels_processed = {l: 0 for l in set(labels)}\n",
    "\n",
    "for finding in tqdm(list_all):\n",
    "    label_ = finding['label']\n",
    "    embedding_ = finding['embedding']\n",
    "    bbox_ = finding['bbox']\n",
    "    landmark_ = finding['landmark']\n",
    "    diautt_ = finding['diautt']\n",
    "    frame_num = finding['frame']\n",
    "    video_path = os.path.join(VIDS_DIR, diautt_) + '.mp4'\n",
    "\n",
    "    os.makedirs(os.path.join('./DEBUG/faces', str(label_)), exist_ok=True)\n",
    "\n",
    "    # if labels_processed[label_] > NUM_MAX_VID_PER_LABEL:\n",
    "    #     continue\n",
    "\n",
    "    assert os.path.isfile(video_path)\n",
    "\n",
    "    container = av.open(video_path)\n",
    "    for idx, frame in enumerate(container.decode(video=0)):\n",
    "        img = np.array(frame.to_image())\n",
    "\n",
    "        if idx == frame_num:\n",
    "            break\n",
    "\n",
    "    batch = img[np.newaxis, ...]\n",
    "    face = fd.crop_and_align(batch, [bbox_[np.newaxis, ...]], [landmark_[np.newaxis, ...]])\n",
    "    face = np.squeeze(face)\n",
    "\n",
    "    img_write_path = os.path.join('./DEBUG/faces', \n",
    "                                  str(label_), \n",
    "                                  f\"{diautt_}_frame{frame_num}_{'_'.join([str(foo) for foo in bbox_.astype(np.int).tolist()[:4]])}.jpg\")\n",
    "\n",
    "    cv2.imwrite(img_write_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "    labels_processed[label_] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import av\n",
    "import random\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "\n",
    "labels = np.load(\"./DEBUG/embeddings-clusters.npy\")\n",
    "embeddings_all = np.load(\"./DEBUG/embeddings-all.npy\")\n",
    "\n",
    "assert len(labels) == len(embeddings_all)"
   ]
  },
  {
   "source": [
    "# I got below after going through all of them\n",
    "\n",
    "# 1\tRachel\n",
    "# 2\tChandler\n",
    "# 3\tJoey\n",
    "# 4\tRoss\n",
    "# 5\tPhoebe\n",
    "# 9\tBen\n",
    "# 11\tMonica\n",
    "# 12\tLeslie\n",
    "# 13\tMonica\n",
    "# 14\tMischa\n",
    "# 19\tRichard\n",
    "# 21\tDanny\n",
    "# 22\tTom\n",
    "# 28\tKatie\n",
    "# 30\tDr. Ledbetter\n",
    "# 31\tDr. Green\n",
    "# 32\tMona\n",
    "# 42\tHoshi\n",
    "# 44\tPete\n",
    "# 48\tReceptionist\n",
    "# 51\tCharlie\n",
    "# 53\tRick\n",
    "\n",
    "to_keep = {'Rachel': [],\n",
    "'Chandler': [],\n",
    "'Joey': [],\n",
    "'Ross': [],\n",
    "'Phoebe': [],\n",
    "'Ben': [],\n",
    "'Monica': [],\n",
    "'Leslie': [],\n",
    "'Mischa': [],\n",
    "'Richard': [],\n",
    "'Danny': [],\n",
    "'Tom': [],\n",
    "'Katie': [],\n",
    "'Dr. Ledbetter': [],\n",
    "'Dr. Green': [],\n",
    "'Mona': [],\n",
    "'Hoshi': [],\n",
    "'Pete': [],\n",
    "'Receptionist': [],\n",
    "'Charlie': [],\n",
    "'Rick': []}\n",
    "\n",
    "label2name = {\n",
    "1:'Rachel',\n",
    "2:'Chandler',\n",
    "3:'Joey',\n",
    "4:'Ross',\n",
    "5:'Phoebe',\n",
    "9:'Ben',\n",
    "11:'Monica',\n",
    "12:'Leslie',\n",
    "14:'Mischa',\n",
    "19:'Richard',\n",
    "21:'Danny',\n",
    "22:'Tom',\n",
    "28:'Katie',\n",
    "30:'Dr. Ledbetter',\n",
    "31:'Dr. Green',\n",
    "32:'Mona',\n",
    "42:'Hoshi',\n",
    "44:'Pete',\n",
    "48:'Receptionist',\n",
    "51:'Charlie',\n",
    "53:'Rick'\n",
    "}\n",
    "assert len(to_keep) == len(label2name)\n",
    "\n",
    "for l, e in zip(labels, embeddings_all):\n",
    "    if l not in list((label2name).keys()):\n",
    "        continue\n",
    "    to_keep[label2name[l]].append(e)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rachel 1821\nChandler 1318\nJoey 2013\nRoss 2470\nPhoebe 1728\nBen 121\nMonica 1393\nLeslie 72\nMischa 89\nRichard 57\nDanny 27\nTom 61\nKatie 49\nDr. Ledbetter 32\nDr. Green 159\nMona 51\nHoshi 36\nPete 23\nReceptionist 114\nCharlie 27\nRick 23\n"
     ]
    }
   ],
   "source": [
    "for key, val in to_keep.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rachel (512,) 1.0000001 float32\nChandler (512,) 0.99999994 float32\nJoey (512,) 0.9999999 float32\nRoss (512,) 1.0000001 float32\nPhoebe (512,) 1.0 float32\nBen (512,) 1.0 float32\nMonica (512,) 0.99999994 float32\nLeslie (512,) 1.0 float32\nMischa (512,) 1.0 float32\nRichard (512,) 1.0 float32\nDanny (512,) 1.0 float32\nTom (512,) 1.0000001 float32\nKatie (512,) 0.9999999 float32\nDr. Ledbetter (512,) 0.99999994 float32\nDr. Green (512,) 1.0000001 float32\nMona (512,) 0.9999998 float32\nHoshi (512,) 1.0000001 float32\nPete (512,) 0.99999994 float32\nReceptionist (512,) 1.0 float32\nCharlie (512,) 1.0 float32\nRick (512,) 1.0 float32\n"
     ]
    }
   ],
   "source": [
    "final_vectors = {}\n",
    "for name, list_of_embs in to_keep.items():\n",
    "    sum_of_vecs = np.sum(list_of_embs, axis=0)\n",
    "    sum_of_vecs = sum_of_vecs / np.linalg.norm(sum_of_vecs)\n",
    "    print(name, sum_of_vecs.shape, np.linalg.norm(sum_of_vecs), sum_of_vecs.dtype)\n",
    "    final_vectors[name] = sum_of_vecs\n",
    "\n",
    "np.save('DEBUG/friends-embeddings.npy', final_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for name, final_vector in final_vectors.items():\n",
    "    os.makedirs(f'DEBUG/friends/{name}', exist_ok=True)\n",
    "    np.save(f'DEBUG/friends/{name}/{name}.npy', final_vector)"
   ]
  }
 ]
}