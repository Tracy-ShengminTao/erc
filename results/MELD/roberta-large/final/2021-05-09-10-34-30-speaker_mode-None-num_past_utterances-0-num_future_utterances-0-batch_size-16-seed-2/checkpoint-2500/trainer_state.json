{
  "best_metric": 0.6318277979752669,
  "best_model_checkpoint": "results/MELD/roberta-large/SEEDS/2021-05-09-10-34-30-speaker_mode-None-num_past_utterances-0-num_future_utterances-0-batch_size-16-seed-2/checkpoint-2500",
  "epoch": 4.0,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "learning_rate": 8.828624329237281e-06,
      "loss": 1.4355,
      "step": 625
    },
    {
      "epoch": 1.0,
      "eval_f1_macro": 0.3819780457632203,
      "eval_f1_micro": 0.6212804328223624,
      "eval_f1_weighted": 0.5817483403290094,
      "eval_loss": 1.143835425376892,
      "eval_runtime": 2.2039,
      "eval_samples_per_second": 503.202,
      "step": 625
    },
    {
      "epoch": 2.0,
      "learning_rate": 6.707044573221053e-06,
      "loss": 1.057,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_f1_macro": 0.4830107217511766,
      "eval_f1_micro": 0.6447249774571686,
      "eval_f1_weighted": 0.6216811169566648,
      "eval_loss": 1.0678489208221436,
      "eval_runtime": 2.2025,
      "eval_samples_per_second": 503.53,
      "step": 1250
    },
    {
      "epoch": 3.0,
      "learning_rate": 4.478494409338459e-06,
      "loss": 0.8699,
      "step": 1875
    },
    {
      "epoch": 3.0,
      "eval_f1_macro": 0.5011398158554939,
      "eval_f1_micro": 0.6456266907123535,
      "eval_f1_weighted": 0.6280324283507118,
      "eval_loss": 1.0536887645721436,
      "eval_runtime": 2.2087,
      "eval_samples_per_second": 502.099,
      "step": 1875
    },
    {
      "epoch": 4.0,
      "learning_rate": 2.2499442454558665e-06,
      "loss": 0.7178,
      "step": 2500
    },
    {
      "epoch": 4.0,
      "eval_f1_macro": 0.5100948051023187,
      "eval_f1_micro": 0.6402164111812444,
      "eval_f1_weighted": 0.6318277979752669,
      "eval_loss": 1.1096059083938599,
      "eval_runtime": 2.2028,
      "eval_samples_per_second": 503.451,
      "step": 2500
    }
  ],
  "max_steps": 3125,
  "num_train_epochs": 5,
  "total_flos": 704688335973972.0,
  "trial_name": null,
  "trial_params": null
}
