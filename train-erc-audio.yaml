DATASET: MELD
model_checkpoint: roberta-large
num_past_utterances: 1000
num_future_utterances: 0
BATCH_SIZE: 4
HP_ONLY_UPTO: 103
NUM_TRAIN_EPOCHS: 5
WEIGHT_DECAY: 0.01
WARMUP_RATIO: 0.2
HP_N_TRIALS: 5
SEEDS:
- 0
- 1
- 2
- 3
- 4
ADD_BOU: false
ADD_EOU: false
ADD_SPEAKER_TOKENS: true
# REPLACE_NAMES_IN_UTTERANCES: false # having this true had a very bad effect. So weird.
SPEAKER_SPLITS:
 - train
 - val
 - test
spectrogram:
  sr: 22050
  n_mels: 1024      # 128*8
  n_fft: 16384      # 2048*8
  hop_length: 4096  # 512*8
  win_length: null  # If unspecified, defaults to win_length = n_fft