{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdevpython378e162af75d134820b03d49898b79756f",
   "display_name": "Python 3.7.9 64-bit ('dev-python-3.7')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('configs/paths.yaml', 'r') as stream:\n",
    "    PATHS = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "with open(PATHS['ANNOTATIONS']['all'], 'r') as stream:\n",
    "    datasets = yaml.safe_load(stream)\n",
    "\n",
    "visual_features = glob(os.path.join(PATHS['VISUAL_FEATURES']['train'], '*.npy'))\n",
    "visual_features = {os.path.basename(vf).split('.npy')[0] : np.load(vf, allow_pickle=True).item() for vf in visual_features}\n",
    "\n",
    "print(len(visual_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "FACE_PROB = 0.975\n",
    "EVERY_N_FRAME = 16\n",
    "ACTORS = ['Chandler', 'Joey', 'Monica', 'Phoebe', 'Rachel', 'Ross']\n",
    "dataset = datasets['train']\n",
    "\n",
    "speakers_mentioned = []\n",
    "embeddings_all = []\n",
    "\n",
    "# This is gonna help us to find back to the source frame and video\n",
    "idx2source = {}\n",
    "embeddings_all = []\n",
    "bboxes_all = []\n",
    "landmarks_all = []\n",
    "\n",
    "count = 0\n",
    "for diautt, annot in tqdm(dataset.items()):\n",
    "    # There is one face annotated in the entire video.\n",
    "    # We are not even sure if the face is actually there or not.\n",
    "    # Even though the face is there, we are not sure which frame number it is.\n",
    "    try:\n",
    "        if annot['Speaker'] not in ACTORS:\n",
    "            continue\n",
    "\n",
    "        for framenum, list_of_findings in visual_features[diautt].items():\n",
    "            if framenum % EVERY_N_FRAME != 0:\n",
    "                continue\n",
    "            for finding in list_of_findings:\n",
    "                if finding['bbox'][-1] < FACE_PROB:\n",
    "                    continue\n",
    "                \n",
    "                embeddings_all.append(finding['embedding'])\n",
    "                bboxes_all.append(finding['bbox'])\n",
    "                landmarks_all.append(finding['landmark'])\n",
    "                idx2source[count] = {'diautt':diautt, 'frame': framenum}\n",
    "                count+=1\n",
    "                speakers_mentioned.append(annot['Speaker'])\n",
    "    except KeyError as e:\n",
    "        print(f\"{e} doesn't exist\")\n",
    "        continue\n",
    "\n",
    "assert len(embeddings_all) == len(bboxes_all) == len(landmarks_all) == \\\n",
    "        len(idx2source)\n",
    "\n",
    "speakers_mentioned = sorted(list(set(speakers_mentioned)))\n",
    "\n",
    "print(f\"Out of the {len(dataset)} number of videos (utterances),\")\n",
    "print(f\"There are in total of {len(speakers_mentioned)} unique speakers mentioned\")\n",
    "print()\n",
    "print(speakers_mentioned)\n",
    "print()\n",
    "print(f\"and {len(embeddings_all)} faces detected\")\n",
    "\n",
    "os.makedirs('DEBUG', exist_ok=True)\n",
    "np.save('./DEBUG/embeddings-all.npy', embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = np.stack(embeddings_all)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "# DBSCAN uses euclidean distance between the data points.\n",
    "# TODO: find a way to replace it with angle distance.\n",
    "# eps and min_samples are hyper parameters that you have to tune.\n",
    "# At the moment 0.75 and 10, respectively, works decent.\n",
    "db = DBSCAN(eps=0.8, min_samples=100, n_jobs=-1).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "print(f\"Number of faces that are clustered: {len(embeddings_all) - n_noise_}\")\n",
    "print()\n",
    "\n",
    "(label_num, counts) = np.unique(labels, return_counts=True)\n",
    "\n",
    "for l, c in zip(label_num, counts):\n",
    "    print(f\" label {l} \\t has {c} counts\")\n",
    "\n",
    "np.save('./DEBUG/embeddings-clusters.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import av\n",
    "import random\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "\n",
    "labels = np.load(\"./DEBUG/embeddings-clusters.npy\")\n",
    "\n",
    "shutil.rmtree('./DEBUG/faces/', ignore_errors=True)\n",
    "\n",
    "assert len(embeddings_all) == len(bboxes_all) == len(landmarks_all) == \\\n",
    "        len(idx2source) == len(labels)\n",
    "\n",
    "\n",
    "list_all = []\n",
    "\n",
    "\n",
    "indices = list(idx2source.keys())\n",
    "for idx in tqdm(indices):\n",
    "    label_ = labels[idx]\n",
    "\n",
    "    embedding_ = embeddings_all[idx]\n",
    "    bbox_ = bboxes_all[idx]\n",
    "    landmark_ = landmarks_all[idx]\n",
    "    source_ = idx2source[idx]\n",
    "\n",
    "    to_append = {'label': label_, \n",
    "                'embedding': embedding_,\n",
    "                 'bbox': bbox_,\n",
    "                 'landmark': landmark_,\n",
    "                 'diautt': source_['diautt'],\n",
    "                 'frame': source_['frame']}\n",
    "\n",
    "    list_all.append(to_append)\n",
    "\n",
    "\n",
    "assert len(list_all) == len(labels)\n",
    "\n",
    "random.shuffle(list_all)\n",
    "\n",
    "fd = FaceDetection(device='cpu', face_detector='sfd')\n",
    "\n",
    "\n",
    "\n",
    "for finding in tqdm(list_all):\n",
    "    label_ = finding['label']\n",
    "    embedding_ = finding['embedding']\n",
    "    bbox_ = finding['bbox']\n",
    "    landmark_ = finding['landmark']\n",
    "    diautt_ = finding['diautt']\n",
    "    frame_num = finding['frame']\n",
    "    video_path = os.path.join(PATHS['ORIGINAL_VIDEOS']['train'], diautt_) + '.mp4'\n",
    "\n",
    "    os.makedirs(os.path.join('./DEBUG/faces', str(label_)), exist_ok=True)\n",
    "\n",
    "    if not os.path.isfile(video_path):\n",
    "        continue\n",
    "\n",
    "    container = av.open(video_path)\n",
    "    for idx, frame in enumerate(container.decode(video=0)):\n",
    "        img = np.array(frame.to_image())\n",
    "\n",
    "        if idx == frame_num:\n",
    "            break\n",
    "\n",
    "    batch = img[np.newaxis, ...]\n",
    "    face = fd.crop_and_align(batch, [bbox_[np.newaxis, ...]], [landmark_[np.newaxis, ...]])\n",
    "    face = np.squeeze(face)\n",
    "\n",
    "    img_write_path = os.path.join('./DEBUG/faces',\n",
    "                                str(label_), \n",
    "                                f\"{diautt_}_frame{frame_num}_{'_'.join([str(foo) for foo in bbox_.astype(np.int).tolist()[:4]])}.jpg\")\n",
    "\n",
    "    cv2.imwrite(img_write_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import av\n",
    "import random\n",
    "from cltl_face_all.face_alignment import FaceDetection\n",
    "\n",
    "labels = np.load(\"./DEBUG/embeddings-clusters.npy\")\n",
    "embeddings_all = np.load(\"./DEBUG/embeddings-all.npy\")\n",
    "\n",
    "assert len(labels) == len(embeddings_all)"
   ]
  },
  {
   "source": [
    "# I got below after going through all of them\n",
    "\n",
    "# -1 Random faces\n",
    "# 0 Chandler\n",
    "# 1\tRandom faces\n",
    "# 2\tJoey\n",
    "# 3 Rachel\n",
    "# 4 Monica\n",
    "# 5 Phoebe\n",
    "# 6 Ross\n",
    "# 7 Noise\n",
    "\n",
    "to_keep = {actor: [] for actor in ACTORS}\n",
    "\n",
    "label2name = {\n",
    "    0: 'Chandler',\n",
    "    2: 'Joey',\n",
    "    3: 'Rachel',\n",
    "    4: 'Monica',\n",
    "    5: 'Phoebe',\n",
    "    6: 'Ross'}\n",
    "\n",
    "assert len(to_keep) == len(label2name)\n",
    "\n",
    "for l, e in zip(labels, embeddings_all):\n",
    "    if l not in list((label2name).keys()):\n",
    "        continue\n",
    "    to_keep[label2name[l]].append(e)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in to_keep.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vectors = {}\n",
    "for name, list_of_embs in to_keep.items():\n",
    "    sum_of_vecs = np.sum(list_of_embs, axis=0)\n",
    "    sum_of_vecs = sum_of_vecs / np.linalg.norm(sum_of_vecs)\n",
    "    print(name, sum_of_vecs.shape, np.linalg.norm(sum_of_vecs), sum_of_vecs.dtype)\n",
    "    final_vectors[name] = sum_of_vecs\n",
    "\n",
    "np.save('DEBUG/friends-embeddings.npy', final_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for name, final_vector in final_vectors.items():\n",
    "    os.makedirs(f'DEBUG/friends/{name}', exist_ok=True)\n",
    "    np.save(f'DEBUG/friends/{name}/{name}.npy', final_vector)"
   ]
  }
 ]
}